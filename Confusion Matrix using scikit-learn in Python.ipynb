{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38dd52c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix in sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec600bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual values\n",
    "actual = [1,0,0,1,0,0,1,0,0,1]\n",
    "# predicted values\n",
    "predicted = [1,0,0,1,0,0,0,1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f88c4324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[2 2]\n",
      " [1 5]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(actual,predicted, labels=[1,0])\n",
    "\n",
    "''' Parameters\n",
    "----------\n",
    "y_true : array-like of shape (n_samples,)\n",
    "    Ground truth (correct) target values.\n",
    "\n",
    "y_pred : array-like of shape (n_samples,)\n",
    "    Estimated targets as returned by a classifier.\n",
    "\n",
    "labels : array-like of shape (n_classes), default=None\n",
    "    List of labels to index the matrix. This may be used to reorder\n",
    "    or select a subset of labels.\n",
    "    If ``None`` is given, those that appear at least once\n",
    "    in ``y_true`` or ``y_pred`` are used in sorted order'''\n",
    "\n",
    "print('Confusion matrix : \\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42b8e264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome values : \n",
      " 2 2 1 5\n"
     ]
    }
   ],
   "source": [
    "# outcome values order in sklearn\n",
    "#Compute confusion matrix to evaluate the accuracy of a classification.\n",
    "tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b9584b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.50      0.57         4\n",
      "           0       0.71      0.83      0.77         6\n",
      "\n",
      "    accuracy                           0.70        10\n",
      "   macro avg       0.69      0.67      0.67        10\n",
      "weighted avg       0.70      0.70      0.69        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for precision, recall f1-score and accuracy\n",
    "#Build a text report showing the main classification metrics.\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n',matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21473405",
   "metadata": {},
   "source": [
    "# Sklearn has two great functions: confusion_matrix() and classification_report().\n",
    "\n",
    "* Sklearn confusion_matrix() returns the values of the Confusion matrix. The output is, however, slightly different from what we have studied so far. It takes the rows as Actual values and the columns as Predicted values. The rest of the concept remains the same.\n",
    "* Sklearn classification_report() outputs precision, recall and f1-score for each target class. In addition to this, it also has some extra values: micro avg, macro avg, and weighted avg\n",
    "* Mirco average is the precision/recall/f1-score calculated for all the classes.\n",
    "* Macro average is the average of precision/recall/f1-score\n",
    "* Weighted average is just the weighted average of precision/recall/f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b8e16e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
